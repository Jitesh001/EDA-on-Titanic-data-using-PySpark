{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae7c770",
   "metadata": {},
   "source": [
    "### Creating Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2b82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d030dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff923547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pyspark.sql.functions import count, mean, when, lit, create_map, regexp_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24a658",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d14f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = spark.read.csv('train.csv', inferSchema=True, header=True)\n",
    "data2 = spark.read.csv('test.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25f939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what information dataset contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88e42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a374f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing sample 5 records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033a310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3855bd4",
   "metadata": {},
   "source": [
    "**Let's see summary of some important columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1c6185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "|summary|           Survived|            Pclass|               Age|             Fare|\n",
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "|  count|                891|               891|               714|              891|\n",
      "|   mean| 0.3838383838383838| 2.308641975308642| 29.69911764705882| 32.2042079685746|\n",
      "| stddev|0.48659245426485753|0.8360712409770491|14.526497332334035|49.69342859718089|\n",
      "|    min|                  0|                 1|              0.42|              0.0|\n",
      "|    25%|                  0|                 2|              20.0|           7.8958|\n",
      "|    50%|                  0|                 3|              28.0|          14.4542|\n",
      "|    75%|                  1|                 3|              38.0|             31.0|\n",
      "|    max|                  1|                 3|              80.0|         512.3292|\n",
      "+-------+-------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.select('Survived', 'Pclass', 'Age', 'Fare').summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe90b72",
   "metadata": {},
   "source": [
    "here we can see the average age of person is close to 30 with minimum age of 0.4 and maximum age of 80yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bff3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows :  891\n",
      "Number of Columns :  12\n"
     ]
    }
   ],
   "source": [
    "print('Number of Rows : ', data1.count())\n",
    "print('Number of Columns : ', len(data1.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ab557",
   "metadata": {},
   "source": [
    "dataset contains total 891 records with 12 different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37795587",
   "metadata": {},
   "source": [
    "**How many people survived?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb26993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Survived').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f76e9",
   "metadata": {},
   "source": [
    "Out of 891 people 342 survived and 549 lost their lives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c8609",
   "metadata": {},
   "source": [
    "**Average fare and age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e2fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+\n",
      "|Survived|         avg(Fare)|          avg(Age)|\n",
      "+--------+------------------+------------------+\n",
      "|       1| 48.39540760233917|28.343689655172415|\n",
      "|       0|22.117886885245877| 30.62617924528302|\n",
      "+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Survived').mean('Fare', 'Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717acb1",
   "metadata": {},
   "source": [
    "here we can see people with chepeaset fare (less money) are likely to died and those with high fair fare are survived. \n",
    "age also matters here !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499e6a6",
   "metadata": {},
   "source": [
    "**Number of male/female survived**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "055c1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+\n",
      "|Survived|female|male|\n",
      "+--------+------+----+\n",
      "|       1|   233| 109|\n",
      "|       0|    81| 468|\n",
      "+--------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Survived').pivot('sex').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce0e44",
   "metadata": {},
   "source": [
    "Number of women died are much less than men, which shows women are given priority while rescuing. Also, number of female \n",
    "survived are more than male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8be4253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+---+---+---+---+----+----+\n",
      "|Survived|  0|  1|  2|  3|  4|   5|   8|\n",
      "+--------+---+---+---+---+---+----+----+\n",
      "|       1|210|112| 13|  4|  3|null|null|\n",
      "|       0|398| 97| 15| 12| 15|   5|   7|\n",
      "+--------+---+---+---+---+---+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Survived').pivot('SibSp').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b0004d",
   "metadata": {},
   "source": [
    "person travelling alone is likely to die. Which shows number of people travelling together also matters during accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837f4cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---+---+---+\n",
      "|Survived|null|  C|  Q|  S|\n",
      "+--------+----+---+---+---+\n",
      "|       1|   2| 93| 30|217|\n",
      "|       0|null| 75| 47|427|\n",
      "+--------+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Survived').pivot('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becef648",
   "metadata": {},
   "source": [
    "**Let's see if we have missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894246be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId     0\n",
      "Survived        0\n",
      "Pclass          0\n",
      "Name            0\n",
      "Sex             0\n",
      "Age             177\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Ticket          0\n",
      "Fare            0\n",
      "Cabin           687\n",
      "Embarked        2\n"
     ]
    }
   ],
   "source": [
    "for col in data1.columns:\n",
    "    print(col.ljust(15), data1.filter(data1[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff520c4",
   "metadata": {},
   "source": [
    "columns **Cabin , Embarked and Sex** have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f6664",
   "metadata": {},
   "source": [
    "There are many Cabin info is missing. The Cabin is related to Pclass. We will drop this feature. So no problem so far. There are, 2 entries of Embarked missing. We will fill it with the most repeated value S. Age of many people is missing. Again the simplest way to impute the age would be to fill by the average. We choose median for fare imputation. We use Spark's fillna() method to do that. For age we use more complex imputation method discussed below. For now I am just focusing on the train data. There can be different feature missing in the test data. Acutally there is missed fair in test data. So we calculate median fair also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f7dd86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------------+\n",
      "|summary|Embarked|            Fare|\n",
      "+-------+--------+----------------+\n",
      "|   mean|    null|32.2042079685746|\n",
      "|    50%|    null|         14.4542|\n",
      "|    max|       S|        512.3292|\n",
      "+-------+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.select('Embarked', 'Fare').summary('mean', '50%', 'max').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10489526",
   "metadata": {},
   "source": [
    "**Let's Fill Null values based on above information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04e8b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.fillna({'Embarked':'S', 'Fare':14.45})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed402d",
   "metadata": {},
   "source": [
    "The basic idea for age imputation is to take the title of the people from the name column and impute with the average age of the group of people with that title. Mrs tend to be older than Miss. \n",
    "\n",
    "First, we extract the title using the regular expression and observe the count and average age with each of the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793d2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.withColumn('Title', regexp_extract(data1['Name'],'([A-Za-z]+)\\.', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "966978a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Title|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|   Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|  Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S| Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|  Mrs|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7fe2b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------+\n",
      "|   Title|count(Age)|          avg(Age)|\n",
      "+--------+----------+------------------+\n",
      "|     Mme|         1|              24.0|\n",
      "|    Capt|         1|              70.0|\n",
      "|     Don|         1|              40.0|\n",
      "|     Sir|         1|              49.0|\n",
      "|    Lady|         1|              48.0|\n",
      "|Jonkheer|         1|              38.0|\n",
      "|      Ms|         1|              28.0|\n",
      "|Countess|         1|              33.0|\n",
      "|   Major|         2|              48.5|\n",
      "|     Col|         2|              58.0|\n",
      "|    Mlle|         2|              24.0|\n",
      "|     Rev|         6|43.166666666666664|\n",
      "|      Dr|         6|              42.0|\n",
      "|  Master|        36| 4.574166666666667|\n",
      "|     Mrs|       108|35.898148148148145|\n",
      "|    Miss|       146|21.773972602739725|\n",
      "|      Mr|       398|32.368090452261306|\n",
      "+--------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.groupBy('Title').agg(count('Age'), mean('Age')).sort('count(Age)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175db646",
   "metadata": {},
   "source": [
    "It is seen that Mr, Miss, and Mrs are highly repeated than other titles. The count of Master is not that high but its average age is much lower than others. So we keep those four titles and map other with one of the first three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b748e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dic = {'Mr':'Mr', 'Miss':'Miss', 'Mrs':'Mrs', 'Master':'Master', \\\n",
    "             'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\\\n",
    "             'Don': 'Mr', 'Mme': 'Miss', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\\\n",
    "             'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs', \\\n",
    "             'Dr':'Mr', 'Rev':'Mr'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c49612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "| Title|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  Miss|             21.86|\n",
      "|Master| 4.574166666666667|\n",
      "|    Mr| 33.02272727272727|\n",
      "|   Mrs|35.981818181818184|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping = create_map([lit(x) for x in chain(*title_dic.items())])\n",
    "\n",
    "data1 = data1.withColumn('Title', mapping[data1['Title']])\n",
    "data1.groupBy('Title').mean('Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be58cf4",
   "metadata": {},
   "source": [
    "Now we create a function that imputes the age column with the average age of the group of people having the same name title as theirs. And use it to impute the ages in the next stage.¬†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96c75dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_age(data, title, req_age):\n",
    "    return data.withColumn('Age', when((data['Age'].isNull()) & (data['Title']==title),req_age).otherwise(data['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d03ad0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = put_age(data1, 'Mr', 33.02)\n",
    "data1 = put_age(data1, 'Mrs', 35.98)\n",
    "data1 = put_age(data1, 'Miss', 21.86)\n",
    "data1 = put_age(data1, 'Master', 4.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd47f19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|  Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked| Title|\n",
      "+-----------+--------+------+--------------------+------+-----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22.0|    1|    0|       A/5 21171|   7.25| null|       S|    Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38.0|    1|    0|        PC 17599|71.2833|  C85|       C|   Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|  Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female| 35.0|    1|    0|          113803|   53.1| C123|       S|   Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male| 35.0|    0|    0|          373450|   8.05| null|       S|    Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|33.02|    0|    0|          330877| 8.4583| null|       Q|    Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male| 54.0|    0|    0|           17463|51.8625|  E46|       S|    Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|  2.0|    3|    1|          349909| 21.075| null|       S|Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female| 27.0|    0|    2|          347742|11.1333| null|       S|   Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female| 14.0|    1|    0|          237736|30.0708| null|       C|   Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|  4.0|    1|    1|         PP 9549|   16.7|   G6|       S|  Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female| 58.0|    0|    0|          113783|  26.55| C103|       S|  Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male| 20.0|    0|    0|       A/5. 2151|   8.05| null|       S|    Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male| 39.0|    1|    5|          347082| 31.275| null|       S|    Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female| 14.0|    0|    0|          350406| 7.8542| null|       S|  Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female| 55.0|    0|    0|          248706|   16.0| null|       S|   Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|  2.0|    4|    1|          382652| 29.125| null|       Q|Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|33.02|    0|    0|          244373|   13.0| null|       S|    Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female| 31.0|    1|    0|          345763|   18.0| null|       S|   Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|35.98|    0|    0|            2649|  7.225| null|       C|   Mrs|\n",
      "+-----------+--------+------+--------------------+------+-----+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3db060a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId     0\n",
      "Survived        0\n",
      "Pclass          0\n",
      "Name            0\n",
      "Sex             0\n",
      "Age             0\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Ticket          0\n",
      "Fare            0\n",
      "Cabin           687\n",
      "Embarked        0\n",
      "Title           0\n"
     ]
    }
   ],
   "source": [
    "for col in data1.columns:\n",
    "    print(col.ljust(15), data1.filter(data1[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafff25d",
   "metadata": {},
   "source": [
    "So there are no null values except Cabin column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a91dc",
   "metadata": {},
   "source": [
    "Let's create a new column called FamilySize combining Parch and SibSp. We use withColumn() method to do that. The first input in the method is a string of the name of the new column. This creates a new column and also keeps the old columns. We will drop the Parch and SibSp column afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ab4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.withColumn('FamilySize', data1['SibSp']+data1['Parch']).drop('Parch', 'SibSp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b554fd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'Title',\n",
       " 'FamilySize']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aecb38ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+----------------+-------+-----+--------+-----+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|          Ticket|   Fare|Cabin|Embarked|Title|FamilySize|\n",
      "+-----------+--------+------+--------------------+------+----+----------------+-------+-----+--------+-----+----------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|       A/5 21171|   7.25| null|       S|   Mr|         1|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|        PC 17599|71.2833|  C85|       C|  Mrs|         1|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|STON/O2. 3101282|  7.925| null|       S| Miss|         0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|          113803|   53.1| C123|       S|  Mrs|         1|\n",
      "+-----------+--------+------+--------------------+------+----+----------------+-------+-----+--------+-----+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc5601",
   "metadata": {},
   "source": [
    "Let's drop the unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b239104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.drop('PassengerID', 'Cabin', 'Name', 'Ticket', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "add5d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+----------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|FamilySize|\n",
      "+--------+------+------+----+-------+--------+----------+\n",
      "|       0|     3|  male|22.0|   7.25|       S|         1|\n",
      "|       1|     1|female|38.0|71.2833|       C|         1|\n",
      "|       1|     3|female|26.0|  7.925|       S|         0|\n",
      "|       1|     1|female|35.0|   53.1|       S|         1|\n",
      "+--------+------+------+----+-------+--------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2131692e",
   "metadata": {},
   "source": [
    "So, Now we have required data with all the important columns and no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d898570",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db3759",
   "metadata": {},
   "source": [
    "So far we used Spark dataframe available in Spark SQL for EDA and feature engineering. Now we will use the Spark ML library to do ML tasks. \n",
    "Will use the following features :\n",
    "- StringIndexer: Converts string categories to numerical categories. \n",
    "- Vector Assembler: Special to Spark API. convert features to spark accepted numeric data. \n",
    "- Logistic regression based on Ridge and Lasso regularization. \n",
    "- Tree-based ensemble methods: Random forest and Gradient boosting. \n",
    "- Pipeline: It is a big deal for big data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e8d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression,\\\n",
    "                    RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ce637",
   "metadata": {},
   "source": [
    "#### String Indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce1128",
   "metadata": {},
   "source": [
    "We will convert the Sex and Embarked column from string to numeric index. This creates a new column for numeric leaving the original intact. So we will remove them afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23106eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "StringIndex = StringIndexer(inputCols=['Sex', 'Embarked'], outputCols=['SexNum', 'EmbNum'])\n",
    "StringIndex_model = StringIndex.fit(data1)\n",
    "data1_ = StringIndex_model.transform(data1).drop('Sex', 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7c06498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+----------+------+------+\n",
      "|Survived|Pclass| Age|   Fare|FamilySize|SexNum|EmbNum|\n",
      "+--------+------+----+-------+----------+------+------+\n",
      "|       0|     3|22.0|   7.25|         1|   0.0|   0.0|\n",
      "|       1|     1|38.0|71.2833|         1|   1.0|   1.0|\n",
      "|       1|     3|26.0|  7.925|         0|   1.0|   0.0|\n",
      "|       1|     1|35.0|   53.1|         1|   1.0|   0.0|\n",
      "+--------+------+----+-------+----------+------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1_.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a92c46",
   "metadata": {},
   "source": [
    "We can see Newly added columns SexNum and EmbNum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd4cc5",
   "metadata": {},
   "source": [
    "#### Vectorassembler - transform all features in single matrix which spark understands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742736a3",
   "metadata": {},
   "source": [
    "We will apply Vectorassembler on only feature columns i.e except Survived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8442df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VectAssembler = VectorAssembler(inputCols=['Pclass','Age','Fare','FamilySize','SexNum','EmbNum'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c2bf02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,22.0,7.25,1....|       0|\n",
      "|[1.0,38.0,71.2833...|       1|\n",
      "|[3.0,26.0,7.925,0...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VectAssembler = VectorAssembler(inputCols=['Pclass','Age','Fare','FamilySize','SexNum','EmbNum'], outputCol='features')\n",
    "data1_ = VectAssembler.transform(data1_).select('features', 'Survived')\n",
    "data1_.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19519f",
   "metadata": {},
   "source": [
    "Now we split the training data into the train and validation part. We split the data into a 7:3 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a21c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = data1_.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fa66b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+\n",
      "|features             |Survived|\n",
      "+---------------------+--------+\n",
      "|(6,[0,1],[1.0,38.0]) |0       |\n",
      "|(6,[0,1],[1.0,40.0]) |0       |\n",
      "|(6,[0,1],[2.0,33.02])|0       |\n",
      "|(6,[0,1],[2.0,33.02])|0       |\n",
      "+---------------------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda743f",
   "metadata": {},
   "source": [
    "### Linear regression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e37a13",
   "metadata": {},
   "source": [
    "In spark API  ùõº  is eleasticNetParam and  ùúÜ  is regParam. We can make our model Ridge by choosing  ùõº=0  and Lasso by choosing  ùõº=1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc3565",
   "metadata": {},
   "source": [
    "**Ridge regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "002a2621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = LogisticRegression(labelCol='Survived', maxIter=100, \n",
    "                        elasticNetParam=0, # Ridge regression is choosen \n",
    "                        regParam=0.03)\n",
    "\n",
    "lr_model = ridge.fit(train_data)\n",
    "preds = lr_model.transform(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91d1ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='Survived', \n",
    "                                          metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "224c685f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098859315589354"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256bfe1",
   "metadata": {},
   "source": [
    "**Lasso regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2bd484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7908745247148289"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LogisticRegression(labelCol='Survived', \n",
    "                           maxIter=100,\n",
    "                           elasticNetParam=1, # Lasso\n",
    "                           regParam=0.0003)\n",
    "\n",
    "model = lasso.fit(train_data)\n",
    "pred = model.transform(valid_data)\n",
    "\n",
    "evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d407f97",
   "metadata": {},
   "source": [
    "Ridge performed well on train dataset than Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615d4de",
   "metadata": {},
   "source": [
    "### test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b88a86b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc1f2121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId     0\n",
      "Pclass          0\n",
      "Name            0\n",
      "Sex             0\n",
      "Age             86\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Ticket          0\n",
      "Fare            1\n",
      "Cabin           327\n",
      "Embarked        0\n"
     ]
    }
   ],
   "source": [
    "for col in data2.columns:\n",
    "    print(col.ljust(15), data2.filter(data2[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "078a40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "| Title|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  Miss|21.774843750000002|\n",
      "|Master| 7.406470588235294|\n",
      "|    Mr|32.340425531914896|\n",
      "|   Mrs|38.904761904761905|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = data2.withColumn('Title', regexp_extract(data2['Name'],'([A-Za-z]+)\\.', 1))\n",
    "mapping = create_map([lit(x) for x in chain(*title_dic.items())])\n",
    "\n",
    "data2 = data2.withColumn('Title', mapping[data2['Title']])\n",
    "data2.groupBy('Title').mean('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9186287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = put_age(data2, 'Mr', 32.34)\n",
    "data2 = put_age(data2, 'Mrs', 38.90)\n",
    "data2 = put_age(data2, 'Miss', 21.77)\n",
    "data2 = put_age(data2, 'Master', 7.41)\n",
    "\n",
    "data2 = data2.withColumn('FamilySize', data2['SibSp']+data2['Parch']).drop('Parch', 'SibSp')\n",
    "data2 = data2.drop('PassengerID', 'Cabin', 'Name', 'Ticket', 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a05ee994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+------+--------+----------+\n",
      "|Pclass|   Sex| Age|  Fare|Embarked|FamilySize|\n",
      "+------+------+----+------+--------+----------+\n",
      "|     3|  male|34.5|7.8292|       Q|         0|\n",
      "|     3|female|47.0|   7.0|       S|         1|\n",
      "|     2|  male|62.0|9.6875|       Q|         0|\n",
      "|     3|  male|27.0|8.6625|       S|         0|\n",
      "+------+------+----+------+--------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49d8beb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[3.0,34.5,7.8292,...|\n",
      "|[3.0,47.0,7.0,1.0...|\n",
      "|[2.0,62.0,9.6875,...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "StringIndex_model = StringIndex.fit(data2)\n",
    "data2_ = StringIndex_model.transform(data2).drop('Sex', 'Embarked')\n",
    "\n",
    "data2_ = VectAssembler.transform(data2_).select('features')\n",
    "data2_.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e8d31b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|[3.0,34.5,7.8292,...|[1.74525955071606...|[0.85135389466907...|       0.0|\n",
      "|[3.0,47.0,7.0,1.0...|[0.60075599034216...|[0.64582924585057...|       0.0|\n",
      "|[2.0,62.0,9.6875,...|[1.79303891301258...|[0.85729945215217...|       0.0|\n",
      "|[3.0,27.0,8.6625,...|[1.82230471079401...|[0.86084244431059...|       0.0|\n",
      "|[3.0,22.0,12.2875...|[-0.1646586599166...|[0.45892808987432...|       1.0|\n",
      "|[3.0,14.0,9.225,0...|[1.35890344900389...|[0.79558142164823...|       0.0|\n",
      "|[3.0,30.0,7.6292,...|[-0.4902906299574...|[0.37982510505628...|       1.0|\n",
      "|[2.0,26.0,29.0,2....|[1.07703269074589...|[0.74593203700064...|       0.0|\n",
      "|[3.0,18.0,7.2292,...|[-0.7420480526552...|[0.32255645347785...|       1.0|\n",
      "|[3.0,21.0,24.15,2...|[1.83783109502792...|[0.86269199287453...|       0.0|\n",
      "|[3.0,32.34,7.8958...|[2.01439073115285...|[0.88229975192982...|       0.0|\n",
      "|[1.0,46.0,26.0,0....|[0.59552353169694...|[0.64463149433264...|       0.0|\n",
      "|[1.0,23.0,82.2667...|[-2.3404302005715...|[0.08782944301281...|       1.0|\n",
      "|[2.0,63.0,26.0,1....|[2.26111085270699...|[0.90560463495616...|       0.0|\n",
      "|[1.0,47.0,61.175,...|[-1.4199641798025...|[0.19466719912988...|       1.0|\n",
      "|[2.0,24.0,27.7208...|[-1.3786414261567...|[0.20122728129539...|       1.0|\n",
      "|[2.0,35.0,12.35,0...|[0.82575005982481...|[0.69545555314879...|       0.0|\n",
      "|[3.0,21.0,7.225,0...|[1.44090442678379...|[0.80859466803593...|       0.0|\n",
      "|[3.0,27.0,7.925,1...|[-0.1123621326094...|[0.47193898374663...|       1.0|\n",
      "|[3.0,45.0,7.225,0...|[0.21663009496091...|[0.55394671824374...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ridge regression\n",
    "preds = lr_model.transform(data2_)\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2382138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|[3.0,34.5,7.8292,...|[2.27050514274402...|[0.90640465047680...|       0.0|\n",
      "|[3.0,47.0,7.0,1.0...|[0.88320973414331...|[0.70748691504359...|       0.0|\n",
      "|[2.0,62.0,9.6875,...|[2.41415067311868...|[0.91790001788674...|       0.0|\n",
      "|[3.0,27.0,8.6625,...|[2.21395951120279...|[0.90149609431627...|       0.0|\n",
      "|[3.0,22.0,12.2875...|[-0.2476074391040...|[0.43841247723176...|       1.0|\n",
      "|[3.0,14.0,9.225,0...|[1.51603847443155...|[0.81995438488509...|       0.0|\n",
      "|[3.0,30.0,7.6292,...|[-0.5938187368037...|[0.35575913925498...|       1.0|\n",
      "|[2.0,26.0,29.0,2....|[1.23695294487676...|[0.77503318491687...|       0.0|\n",
      "|[3.0,18.0,7.2292,...|[-1.0632398858213...|[0.25669079529419...|       1.0|\n",
      "|[3.0,21.0,24.15,2...|[2.30427946180217...|[0.90923084254244...|       0.0|\n",
      "|[3.0,32.34,7.8958...|[2.50144867711009...|[0.92424331524728...|       0.0|\n",
      "|[1.0,46.0,26.0,0....|[0.55042398710567...|[0.63423395366441...|       0.0|\n",
      "|[1.0,23.0,82.2667...|[-3.1730639535134...|[0.04019205169654...|       1.0|\n",
      "|[2.0,63.0,26.0,1....|[3.00778845844705...|[0.95292474570649...|       0.0|\n",
      "|[1.0,47.0,61.175,...|[-1.8544690013608...|[0.13534903840531...|       1.0|\n",
      "|[2.0,24.0,27.7208...|[-1.8827861912683...|[0.13206917352897...|       1.0|\n",
      "|[2.0,35.0,12.35,0...|[0.96237763036013...|[0.72359759370345...|       0.0|\n",
      "|[3.0,21.0,7.225,0...|[1.72095890952540...|[0.84825230871659...|       0.0|\n",
      "|[3.0,27.0,7.925,1...|[-0.1906044961189...|[0.45249261784914...|       1.0|\n",
      "|[3.0,45.0,7.225,0...|[0.38453967693606...|[0.59496754952922...|       0.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lasso regression\n",
    "preds = model.transform(data2_)\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89db99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
